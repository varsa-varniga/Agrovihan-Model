{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5e68e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2364 images belonging to 18 classes.\n",
      "Found 588 images belonging to 18 classes.\n",
      "Class Indices: {'01_healthy_paddy': 0, '02_leaf_blast_paddy': 1, '03_bacterial_leaf_blight_paddy': 2, '04_healthy_banana': 3, '05_cordana_banana': 4, '06_sigatoka_banana': 5, '07_Healthy_sugarcane': 6, '08_Mosaic_sugarcane': 7, '09_RedRot_sugarcane': 8, '10_healthy_leaf_groundnut': 9, '11_early_leaf_spot_groundnut': 10, '12_Rust_groundnut': 11, '13_Healthy blackgram': 12, '14_Yellow Mosaic blackgram': 13, '15_Powdery_Mildew_blackgram': 14, '16_tomato_healthy': 15, '17_Tomato_Yellow_Leaf_Curl_Virus': 16, '18_Early_blight_tomato': 17}\n",
      "Epoch 1/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 749ms/step - accuracy: 0.2381 - loss: 2.6863 - val_accuracy: 0.5625 - val_loss: 1.5871 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.5000 - loss: 1.5387 - val_accuracy: 0.5677 - val_loss: 1.5746 - learning_rate: 9.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.6691 - loss: 1.1623 - val_accuracy: 0.7309 - val_loss: 1.0233 - learning_rate: 8.1000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - accuracy: 0.8125 - loss: 0.8217 - val_accuracy: 0.7326 - val_loss: 1.0190 - learning_rate: 7.2900e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8007 - loss: 0.7912 - val_accuracy: 0.7726 - val_loss: 0.8071 - learning_rate: 6.5610e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - accuracy: 0.7188 - loss: 0.7469 - val_accuracy: 0.7760 - val_loss: 0.8052 - learning_rate: 5.9049e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 472ms/step - accuracy: 0.8513 - loss: 0.6185 - val_accuracy: 0.7865 - val_loss: 0.7220 - learning_rate: 5.3144e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.8438 - loss: 0.6707 - val_accuracy: 0.7847 - val_loss: 0.7213 - learning_rate: 4.7830e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 465ms/step - accuracy: 0.8648 - loss: 0.5469 - val_accuracy: 0.7882 - val_loss: 0.6808 - learning_rate: 4.3047e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 161ms/step - accuracy: 0.8438 - loss: 0.4950 - val_accuracy: 0.7899 - val_loss: 0.6799 - learning_rate: 3.8742e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 733ms/step - accuracy: 0.8825 - loss: 0.4966 - val_accuracy: 0.8003 - val_loss: 0.6528 - learning_rate: 3.4868e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.9286 - loss: 0.3393 - val_accuracy: 0.8003 - val_loss: 0.6530 - learning_rate: 3.1381e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 703ms/step - accuracy: 0.8856 - loss: 0.4650 - val_accuracy: 0.8056 - val_loss: 0.6308 - learning_rate: 2.8243e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8438 - loss: 0.4547 - val_accuracy: 0.8038 - val_loss: 0.6307 - learning_rate: 2.5419e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 660ms/step - accuracy: 0.9000 - loss: 0.4309 - val_accuracy: 0.7986 - val_loss: 0.6256 - learning_rate: 2.2877e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.9375 - loss: 0.3370 - val_accuracy: 0.7969 - val_loss: 0.6260 - learning_rate: 2.0589e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 697ms/step - accuracy: 0.9230 - loss: 0.3832 - val_accuracy: 0.7951 - val_loss: 0.6139 - learning_rate: 1.8530e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.9688 - loss: 0.4493 - val_accuracy: 0.7951 - val_loss: 0.6143 - learning_rate: 1.6677e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 650ms/step - accuracy: 0.9138 - loss: 0.3867 - val_accuracy: 0.8003 - val_loss: 0.6029 - learning_rate: 1.5009e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.9062 - loss: 0.3551 - val_accuracy: 0.8003 - val_loss: 0.6030 - learning_rate: 1.3509e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 662ms/step - accuracy: 0.9093 - loss: 0.3787 - val_accuracy: 0.8108 - val_loss: 0.5974 - learning_rate: 1.2158e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.8750 - loss: 0.4590 - val_accuracy: 0.8108 - val_loss: 0.5971 - learning_rate: 1.0942e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 672ms/step - accuracy: 0.8999 - loss: 0.4027 - val_accuracy: 0.8108 - val_loss: 0.5948 - learning_rate: 9.8477e-06\n",
      "Epoch 24/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9688 - loss: 0.3413 - val_accuracy: 0.8108 - val_loss: 0.5949 - learning_rate: 8.8629e-06\n",
      "Epoch 25/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 673ms/step - accuracy: 0.9157 - loss: 0.3810 - val_accuracy: 0.8160 - val_loss: 0.5909 - learning_rate: 7.9766e-06\n",
      "Epoch 26/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.9062 - loss: 0.3758 - val_accuracy: 0.8160 - val_loss: 0.5908 - learning_rate: 7.1790e-06\n",
      "Epoch 27/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 647ms/step - accuracy: 0.9185 - loss: 0.3695 - val_accuracy: 0.8160 - val_loss: 0.5861 - learning_rate: 6.4611e-06\n",
      "Epoch 28/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.9688 - loss: 0.2228 - val_accuracy: 0.8160 - val_loss: 0.5857 - learning_rate: 5.8150e-06\n",
      "Epoch 29/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 656ms/step - accuracy: 0.9062 - loss: 0.3745 - val_accuracy: 0.8194 - val_loss: 0.5831 - learning_rate: 5.2335e-06\n",
      "Epoch 30/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.9375 - loss: 0.2492 - val_accuracy: 0.8194 - val_loss: 0.5830 - learning_rate: 4.7101e-06\n",
      "Epoch 1/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 822ms/step - accuracy: 0.8152 - loss: 0.6294 - val_accuracy: 0.7656 - val_loss: 0.8778 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9375 - loss: 0.2073 - val_accuracy: 0.7604 - val_loss: 0.8688 - learning_rate: 9.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 804ms/step - accuracy: 0.9580 - loss: 0.1681 - val_accuracy: 0.8177 - val_loss: 0.6083 - learning_rate: 8.1000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9688 - loss: 0.1145 - val_accuracy: 0.8194 - val_loss: 0.6015 - learning_rate: 7.2900e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 927ms/step - accuracy: 0.9776 - loss: 0.1096 - val_accuracy: 0.8333 - val_loss: 0.5965 - learning_rate: 6.5610e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.8351 - val_loss: 0.5940 - learning_rate: 5.9049e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 896ms/step - accuracy: 0.9806 - loss: 0.0874 - val_accuracy: 0.8524 - val_loss: 0.5513 - learning_rate: 5.3144e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.9688 - loss: 0.0993 - val_accuracy: 0.8507 - val_loss: 0.5532 - learning_rate: 4.7830e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 766ms/step - accuracy: 0.9822 - loss: 0.0764 - val_accuracy: 0.8490 - val_loss: 0.5268 - learning_rate: 4.3047e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0399 - val_accuracy: 0.8524 - val_loss: 0.5242 - learning_rate: 3.8742e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 952ms/step - accuracy: 0.9831 - loss: 0.0654 - val_accuracy: 0.8681 - val_loss: 0.4842 - learning_rate: 3.4868e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.9643 - loss: 0.0867 - val_accuracy: 0.8681 - val_loss: 0.4830 - learning_rate: 3.1381e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 587ms/step - accuracy: 0.9916 - loss: 0.0507 - val_accuracy: 0.8854 - val_loss: 0.4297 - learning_rate: 2.8243e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.8854 - val_loss: 0.4290 - learning_rate: 2.5419e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 582ms/step - accuracy: 0.9857 - loss: 0.0530 - val_accuracy: 0.8750 - val_loss: 0.4136 - learning_rate: 2.2877e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 0.8750 - val_loss: 0.4131 - learning_rate: 2.0589e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 576ms/step - accuracy: 0.9918 - loss: 0.0450 - val_accuracy: 0.8993 - val_loss: 0.3684 - learning_rate: 1.8530e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0384 - val_accuracy: 0.8993 - val_loss: 0.3672 - learning_rate: 1.6677e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 575ms/step - accuracy: 0.9916 - loss: 0.0544 - val_accuracy: 0.8854 - val_loss: 0.3990 - learning_rate: 1.5009e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0535 - val_accuracy: 0.8872 - val_loss: 0.3979 - learning_rate: 1.3509e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.9954 - loss: 0.0320\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.078832939238055e-06.\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 582ms/step - accuracy: 0.9954 - loss: 0.0321 - val_accuracy: 0.8941 - val_loss: 0.3677 - learning_rate: 1.2158e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0259 - val_accuracy: 0.8941 - val_loss: 0.3676 - learning_rate: 1.0942e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 574ms/step - accuracy: 0.9897 - loss: 0.0424 - val_accuracy: 0.9010 - val_loss: 0.3446 - learning_rate: 9.8477e-06\n",
      "Epoch 24/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0525 - val_accuracy: 0.9010 - val_loss: 0.3442 - learning_rate: 8.8629e-06\n",
      "Epoch 25/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 578ms/step - accuracy: 0.9940 - loss: 0.0341 - val_accuracy: 0.9097 - val_loss: 0.3192 - learning_rate: 7.9766e-06\n",
      "Epoch 26/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9688 - loss: 0.0923 - val_accuracy: 0.9097 - val_loss: 0.3191 - learning_rate: 7.1790e-06\n",
      "Epoch 27/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 569ms/step - accuracy: 0.9964 - loss: 0.0315 - val_accuracy: 0.9097 - val_loss: 0.3075 - learning_rate: 6.4611e-06\n",
      "Epoch 28/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0430 - val_accuracy: 0.9097 - val_loss: 0.3074 - learning_rate: 5.8150e-06\n",
      "Epoch 29/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 566ms/step - accuracy: 0.9953 - loss: 0.0314 - val_accuracy: 0.9184 - val_loss: 0.2943 - learning_rate: 5.2335e-06\n",
      "Epoch 30/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.9688 - loss: 0.0562 - val_accuracy: 0.9184 - val_loss: 0.2940 - learning_rate: 4.7101e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to ../models/mobilenetv2_model.h5\n",
      "✅ History saved successfully! 🎉\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Paths and constants\n",
    "dataset_path = '../dataset/'\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 30  # Increased epochs for better performance\n",
    "model_path = '../models/mobilenetv2_model.h5'\n",
    "\n",
    "# Data generators (already written)\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2],  # Added brightness range for more robustness\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    directory=dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(\"Class Indices:\", train_generator.class_indices)\n",
    "\n",
    "# Build MobileNetV2 model\n",
    "base_model = MobileNetV2(input_shape=(img_height, img_width, 3),\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "\n",
    "base_model.trainable = False  # Freeze the base model initially\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # Adding batch normalization\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = LearningRateScheduler(lambda epoch: 0.0001 * 0.9 ** epoch)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, lr_scheduler, reduce_lr]\n",
    ")\n",
    "\n",
    "# Fine-tuning (optional): Unfreeze more layers of MobileNetV2\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100  # Unfreeze from this layer onward, can adjust further\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model after unfreezing layers\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),  # Lower learning rate for fine-tuning\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue training the model with fine-tuning\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, lr_scheduler, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "model.save(model_path)\n",
    "print(f\"✅ Model saved to {model_path}\")\n",
    "\n",
    "# Save history\n",
    "with open('../models/history.pkl', 'wb') as f:\n",
    "    pickle.dump(history_finetune.history, f)\n",
    "\n",
    "print(\"✅ History saved successfully! 🎉\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb11cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97233464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\varsa\\anaconda3\\envs\\plantvillage\\lib\\site-packages (11.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2301 images belonging to 6 classes.\n",
      "Found 573 images belonging to 6 classes.\n",
      "Class Indices: {'Banana': 0, 'Blackgram': 1, 'Groundnut': 2, 'Paddy': 3, 'Sugarcane': 4, 'Tomato': 5}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 76\u001b[0m\n\u001b[0;32m     71\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[0;32m     72\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     73\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m     83\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\varsa\\anaconda3\\envs\\plantvillage\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\varsa\\anaconda3\\envs\\plantvillage\\lib\\site-packages\\keras\\src\\utils\\image_utils.py:227\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    A PIL Image instance.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import PIL.Image. The use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m     )\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io\u001b[38;5;241m.\u001b[39mBytesIO):\n\u001b[0;32m    231\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(path)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fada8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pillow 11.2.1\n",
      "Uninstalling pillow-11.2.1:\n",
      "  Successfully uninstalled pillow-11.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\varsa\\anaconda3\\envs\\plantvillage\\Lib\\site-packages\\~il'.\n",
      "You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f68959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-11.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e498be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2364 images belonging to 18 classes.\n",
      "Found 588 images belonging to 18 classes.\n",
      "Class Indices: {'01_healthy_paddy': 0, '02_leaf_blast_paddy': 1, '03_bacterial_leaf_blight_paddy': 2, '04_healthy_banana': 3, '05_cordana_banana': 4, '06_sigatoka_banana': 5, '07_Healthy_sugarcane': 6, '08_Mosaic_sugarcane': 7, '09_RedRot_sugarcane': 8, '10_healthy_leaf_groundnut': 9, '11_early_leaf_spot_groundnut': 10, '12_Rust_groundnut': 11, '13_Healthy blackgram': 12, '14_Yellow Mosaic blackgram': 13, '15_Powdery_Mildew_blackgram': 14, '16_tomato_healthy': 15, '17_Tomato_Yellow_Leaf_Curl_Virus': 16, '18_Early_blight_tomato': 17}\n",
      "Epoch 1/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 568ms/step - accuracy: 0.1728 - loss: 2.7465 - val_accuracy: 0.5486 - val_loss: 1.7349 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.7188 - loss: 1.4922 - val_accuracy: 0.5486 - val_loss: 1.7231 - learning_rate: 9.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 544ms/step - accuracy: 0.6375 - loss: 1.4660 - val_accuracy: 0.7170 - val_loss: 1.1004 - learning_rate: 8.1000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.8125 - loss: 0.9493 - val_accuracy: 0.7188 - val_loss: 1.0941 - learning_rate: 7.2900e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 526ms/step - accuracy: 0.7979 - loss: 0.8938 - val_accuracy: 0.7552 - val_loss: 0.8383 - learning_rate: 6.5610e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.8125 - loss: 0.6944 - val_accuracy: 0.7552 - val_loss: 0.8353 - learning_rate: 5.9049e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 528ms/step - accuracy: 0.8667 - loss: 0.6713 - val_accuracy: 0.7691 - val_loss: 0.7273 - learning_rate: 5.3144e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.9688 - loss: 0.4372 - val_accuracy: 0.7691 - val_loss: 0.7270 - learning_rate: 4.7830e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 814ms/step - accuracy: 0.8796 - loss: 0.5617 - val_accuracy: 0.7830 - val_loss: 0.6715 - learning_rate: 4.3047e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 100ms/step - accuracy: 0.9062 - loss: 0.4770 - val_accuracy: 0.7847 - val_loss: 0.6705 - learning_rate: 3.8742e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 533ms/step - accuracy: 0.9046 - loss: 0.4754 - val_accuracy: 0.7882 - val_loss: 0.6297 - learning_rate: 3.4868e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.8750 - loss: 0.5636 - val_accuracy: 0.7847 - val_loss: 0.6295 - learning_rate: 3.1381e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 521ms/step - accuracy: 0.9085 - loss: 0.4373 - val_accuracy: 0.8090 - val_loss: 0.6003 - learning_rate: 2.8243e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.9688 - loss: 0.2802 - val_accuracy: 0.8090 - val_loss: 0.5998 - learning_rate: 2.5419e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 589ms/step - accuracy: 0.9193 - loss: 0.4047 - val_accuracy: 0.8038 - val_loss: 0.5845 - learning_rate: 2.2877e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.8750 - loss: 0.4100 - val_accuracy: 0.8056 - val_loss: 0.5841 - learning_rate: 2.0589e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 587ms/step - accuracy: 0.9131 - loss: 0.3770 - val_accuracy: 0.8125 - val_loss: 0.5718 - learning_rate: 1.8530e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9062 - loss: 0.3072 - val_accuracy: 0.8142 - val_loss: 0.5713 - learning_rate: 1.6677e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 593ms/step - accuracy: 0.9181 - loss: 0.3746 - val_accuracy: 0.8125 - val_loss: 0.5669 - learning_rate: 1.5009e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.9062 - loss: 0.3544 - val_accuracy: 0.8125 - val_loss: 0.5670 - learning_rate: 1.3509e-05\n",
      "Epoch 1/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 736ms/step - accuracy: 0.8463 - loss: 0.5646 - val_accuracy: 0.6840 - val_loss: 0.9553 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.9375 - loss: 0.1767 - val_accuracy: 0.6806 - val_loss: 0.9578 - learning_rate: 9.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 715ms/step - accuracy: 0.9727 - loss: 0.1176 - val_accuracy: 0.7274 - val_loss: 0.8515 - learning_rate: 8.1000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.9375 - loss: 0.1548 - val_accuracy: 0.7274 - val_loss: 0.8685 - learning_rate: 7.2900e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 719ms/step - accuracy: 0.9838 - loss: 0.0727 - val_accuracy: 0.7135 - val_loss: 0.8473 - learning_rate: 6.5610e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.9375 - loss: 0.1040 - val_accuracy: 0.7188 - val_loss: 0.8423 - learning_rate: 5.9049e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 848ms/step - accuracy: 0.9860 - loss: 0.0524 - val_accuracy: 0.7292 - val_loss: 0.8126 - learning_rate: 5.3144e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.7240 - val_loss: 0.8177 - learning_rate: 4.7830e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.9911 - loss: 0.0384 - val_accuracy: 0.7726 - val_loss: 0.6987 - learning_rate: 4.3047e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 0.9688 - loss: 0.0397 - val_accuracy: 0.7708 - val_loss: 0.7049 - learning_rate: 3.8742e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9921 - loss: 0.0303 - val_accuracy: 0.8108 - val_loss: 0.5936 - learning_rate: 3.4868e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8108 - val_loss: 0.5912 - learning_rate: 3.1381e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 958ms/step - accuracy: 0.9948 - loss: 0.0232 - val_accuracy: 0.8073 - val_loss: 0.6331 - learning_rate: 2.8243e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.9688 - loss: 0.0456 - val_accuracy: 0.8090 - val_loss: 0.6382 - learning_rate: 2.5419e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 696ms/step - accuracy: 0.9980 - loss: 0.0202 - val_accuracy: 0.8559 - val_loss: 0.4750 - learning_rate: 2.2877e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0168 - val_accuracy: 0.8559 - val_loss: 0.4716 - learning_rate: 2.0589e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0169 - val_accuracy: 0.8715 - val_loss: 0.4461 - learning_rate: 1.8530e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 223ms/step - accuracy: 0.9688 - loss: 0.1061 - val_accuracy: 0.8698 - val_loss: 0.4464 - learning_rate: 1.6677e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 3s/step - accuracy: 0.9955 - loss: 0.0185 - val_accuracy: 0.8785 - val_loss: 0.4503 - learning_rate: 1.5009e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.8785 - val_loss: 0.4484 - learning_rate: 1.3509e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to ../models/mobilenetv2_model.h5\n",
      "✅ History saved successfully! 🎉\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04bc69b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pillow 11.2.1\n",
      "Uninstalling pillow-11.2.1:\n",
      "  Successfully uninstalled pillow-11.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping PIL as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall pillow PIL PILLOW -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fbc78dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PillowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-11.2.1\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa6a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pillow is working!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "print(\"✅ Pillow is working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc5486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\varsa\\anaconda3\\envs\\plantvillage\\lib\\site-packages (from scipy) (2.0.2)\n",
      "Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.1/46.2 MB 11.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.2/46.2 MB 13.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.7/46.2 MB 14.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 11.8/46.2 MB 14.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.3/46.2 MB 16.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 19.1/46.2 MB 15.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.5/46.2 MB 16.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.2/46.2 MB 16.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.4/46.2 MB 16.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 32.0/46.2 MB 15.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 35.1/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.3/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.2/46.2 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 15.6 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c5083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plantvillage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
